{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLKDE: Estimação de Densidade e Detecção de Outliers em Preços do Airbnb em Lisboa\n",
        "\n",
        "**Objetivo:** mostrar de forma rápida o que é KDE, como a largura de banda pode ser escolhida por máxima verossimilhança leave-one-out (MLKDE) e aplicar ao dataset do Airbnb em Lisboa para entender a distribuição de preços e destacar outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset em 1 minuto\n",
        "- Dados públicos do [Inside Airbnb](http://insideairbnb.com/get-the-data/) para Lisboa.\n",
        "- Usaremos apenas a coluna **price** e criaremos `log_price` para lidar com a cauda longa.\n",
        "- O download é automático: pega sempre o arquivo mais recente e salva em `data/listings_lisboa.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import gzip\n",
        "import io\n",
        "import re\n",
        "import shutil\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from KDEpy import bw_selection\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "\n",
        "\n",
        "def download_latest_lisbon_listing(destination: Path) -> Path:\n",
        "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if destination.exists():\n",
        "        print(f\"Arquivo já encontrado em {destination}. Usando versão local.\")\n",
        "        return destination\n",
        "\n",
        "    index_url = \"http://insideairbnb.com/get-the-data/\"\n",
        "    with urllib.request.urlopen(index_url, timeout=15) as resp:\n",
        "        html = resp.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "    match = re.search(\n",
        "        r\"https://data\\\\.insideairbnb\\\\.com/portugal/lisbon/lisbon/[0-9-]+/data/listings\\\\.csv\\\\.gz\",\n",
        "        html,\n",
        "    )\n",
        "    if not match:\n",
        "        raise RuntimeError(\"Não foi possível localizar o link de Lisboa no Inside Airbnb.\")\n",
        "\n",
        "    download_url = match.group(0)\n",
        "    request = urllib.request.Request(download_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    with urllib.request.urlopen(request, timeout=60) as resp:\n",
        "        compressed_bytes = io.BytesIO(resp.read())\n",
        "\n",
        "    with gzip.open(compressed_bytes, \"rt\", encoding=\"utf-8\") as gz, destination.open(\"w\", encoding=\"utf-8\") as out:\n",
        "        shutil.copyfileobj(gz, out)\n",
        "\n",
        "    print(f\"Arquivo baixado de {download_url}\")\n",
        "    print(f\"Salvo como {destination}\")\n",
        "    return destination\n",
        "\n",
        "\n",
        "data_path = Path(\"data/listings_lisboa.csv\")\n",
        "try:\n",
        "    download_latest_lisbon_listing(data_path)\n",
        "except Exception as exc:\n",
        "    raise RuntimeError(\n",
        "        \"Não foi possível baixar o dataset automaticamente. Baixe o listings.csv de Lisboa no Inside Airbnb e salve como data/listings_lisboa.csv.\"\n",
        "    ) from exc\n",
        "\n",
        "raw_df = pd.read_csv(data_path)\n",
        "prices = (\n",
        "    raw_df[\"price\"]\n",
        "    .astype(str)\n",
        "    .str.replace(r\"[^0-9,\\\\.]\", \"\", regex=True)\n",
        "    .str.replace(\",\", \"\", regex=False)\n",
        ")\n",
        "prices = pd.to_numeric(prices, errors=\"coerce\")\n",
        "\n",
        "clean_df = raw_df.copy()\n",
        "clean_df[\"price\"] = prices\n",
        "clean_df = clean_df.dropna(subset=[\"price\"]).copy()\n",
        "clean_df = clean_df[clean_df[\"price\"] > 0].copy()\n",
        "clean_df[\"log_price\"] = np.log(clean_df[\"price\"])\n",
        "\n",
        "clean_df[[\"price\", \"log_price\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KDE e a função objetivo (rapidinho)\n",
        "- **KDE**: jeito de desenhar uma curva suave que representa a distribuição dos dados, sem assumir forma prévia.\n",
        "- Fórmula (kernel Gaussiano): \\(\\hat f_h(x) = \\frac{1}{n h} \\sum_{i=1}^n K\\!\\left(\\frac{x - x_i}{h}\\right)\\), com \\(K\\) Gaussiano e **h** controlando a suavidade.\n",
        "- **MLKDE**: para cada \\(h\\), calculamos a log-verossimilhança leave-one-out (quão prováveis os dados ficam sob a curva) e escolhemos o \\(h\\) que a maximiza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def gaussian_kernel(u: np.ndarray) -> np.ndarray:\n",
        "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * u ** 2)\n",
        "\n",
        "\n",
        "def kde_density(x_grid: np.ndarray, data: np.ndarray, bandwidth: float) -> np.ndarray:\n",
        "    scaled = (x_grid[:, None] - data[None, :]) / bandwidth\n",
        "    return gaussian_kernel(scaled).mean(axis=1) / bandwidth\n",
        "\n",
        "\n",
        "def loo_log_likelihood(data: np.ndarray, bandwidth: float) -> float:\n",
        "    if bandwidth <= 0:\n",
        "        return -np.inf\n",
        "    n = data.shape[0]\n",
        "    scaled = (data[:, None] - data[None, :]) / bandwidth\n",
        "    kernels = gaussian_kernel(scaled)\n",
        "    np.fill_diagonal(kernels, 0.0)\n",
        "    density_i = kernels.sum(axis=1) / ((n - 1) * bandwidth)\n",
        "    density_i = np.maximum(density_i, 1e-12)\n",
        "    return float(np.sum(np.log(density_i)))\n",
        "\n",
        "\n",
        "log_prices = clean_df[\"log_price\"].to_numpy()\n",
        "std_log = np.std(log_prices, ddof=1) if len(log_prices) > 1 else 1.0\n",
        "\n",
        "h_min = max(0.05, 0.1 * std_log)\n",
        "h_max = max(h_min * 2, 1.5 * std_log)\n",
        "h_grid = np.linspace(h_min, h_max, 40)\n",
        "\n",
        "log_liks = [loo_log_likelihood(log_prices, h) for h in h_grid]\n",
        "best_idx = int(np.argmax(log_liks))\n",
        "h_mlkde = h_grid[best_idx]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.plot(h_grid, log_liks, label=\"Log-verossimilhança LOO\")\n",
        "ax.axvline(h_mlkde, color=\"crimson\", linestyle=\"--\", label=f\"h ótimo = {h_mlkde:.3f}\")\n",
        "ax.set_xlabel(\"Bandwidth h\")\n",
        "ax.set_ylabel(\"Log-verossimilhança LOO\")\n",
        "ax.set_title(\"Busca do bandwidth por MLKDE\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O pico indica o **h** que deixa os dados mais prováveis segundo o KDE. É esse valor (linha vermelha) que usaremos adiante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "x_grid = np.linspace(log_prices.min() - 0.5, log_prices.max() + 0.5, 400)\n",
        "mlkde_density = kde_density(x_grid, log_prices, h_mlkde)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.hist(log_prices, bins=40, density=True, alpha=0.4, color=\"steelblue\", edgecolor=\"white\")\n",
        "ax.plot(x_grid, mlkde_density, color=\"crimson\", linewidth=2, label=\"KDE (h ótimo)\")\n",
        "ax.set_title(\"Distribuição de log(preço) com curva KDE (h ótimo por MLKDE)\")\n",
        "ax.set_xlabel(\"log(preço)\")\n",
        "ax.set_ylabel(\"Densidade\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "price_grid = np.linspace(clean_df[\"price\"].quantile(0.01), clean_df[\"price\"].quantile(0.99), 400)\n",
        "log_grid = np.log(price_grid)\n",
        "price_density = kde_density(log_grid, log_prices, h_mlkde) / price_grid\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.hist(clean_df[\"price\"], bins=40, density=True, alpha=0.4, color=\"seagreen\", edgecolor=\"white\")\n",
        "ax.plot(price_grid, price_density, color=\"darkgreen\", linewidth=2, label=\"KDE em preços\")\n",
        "ax.set_title(\"Preços em escala original\")\n",
        "ax.set_xlabel(\"Preço por noite (EUR)\")\n",
        "ax.set_ylabel(\"Densidade\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A maior parte dos valores se concentra em uma faixa intermediária; a curva KDE suaviza o histograma e destaca a cauda longa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "\n",
        "def lscv_objective(data: np.ndarray, bandwidth: float) -> float:\n",
        "    if bandwidth <= 0:\n",
        "        return np.inf\n",
        "    n = data.size\n",
        "    diff = data[:, None] - data[None, :]\n",
        "    term1 = np.exp(-(diff ** 2) / (4 * bandwidth ** 2)).sum()\n",
        "    term1 = term1 / (n ** 2 * bandwidth * np.sqrt(4 * np.pi))\n",
        "\n",
        "    gauss = np.exp(-(diff ** 2) / (2 * bandwidth ** 2))\n",
        "    off_sum = gauss.sum() - np.diag(gauss).sum()\n",
        "    term2 = (2 / (n * (n - 1) * bandwidth * np.sqrt(2 * np.pi))) * off_sum\n",
        "    return term1 - term2\n",
        "\n",
        "\n",
        "def score_methods(data: np.ndarray, candidates: Sequence[float]):\n",
        "    loglik = [loo_log_likelihood(data, h) for h in candidates]\n",
        "    best_h = candidates[int(np.argmax(loglik))]\n",
        "    h_lscv_candidates = np.linspace(h_min, h_max, 50)\n",
        "    lscv_vals = [lscv_objective(data, h) for h in h_lscv_candidates]\n",
        "    h_lscv = h_lscv_candidates[int(np.argmin(lscv_vals))]\n",
        "    h_plugin = float(bw_selection.improved_sheather_jones(data))\n",
        "\n",
        "    methods = {\n",
        "        \"MLKDE\": best_h,\n",
        "        \"LSCV\": h_lscv,\n",
        "        \"Plug-in (Sheather–Jones)\": h_plugin,\n",
        "    }\n",
        "    summary = pd.DataFrame(\n",
        "        {\n",
        "            \"metodo\": list(methods.keys()),\n",
        "            \"h\": [methods[m] for m in methods],\n",
        "            \"log_verossimilhanca_loo\": [loo_log_likelihood(data, h) for h in methods.values()],\n",
        "        }\n",
        "    ).sort_values(\"log_verossimilhanca_loo\", ascending=False)\n",
        "    return summary, methods\n",
        "\n",
        "\n",
        "comparacao_h, metodo_h = score_methods(log_prices, h_grid)\n",
        "comparacao_h"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.hist(log_prices, bins=40, density=True, alpha=0.3, color=\"gray\", edgecolor=\"white\", label=\"Histograma\")\n",
        "colors = {\"MLKDE\": \"crimson\", \"LSCV\": \"navy\", \"Plug-in (Sheather–Jones)\": \"darkorange\"}\n",
        "for nome, h in metodo_h.items():\n",
        "    ax.plot(x_grid, kde_density(x_grid, log_prices, h), color=colors[nome], linewidth=2, label=f\"{nome} (h={h:.3f})\")\n",
        "\n",
        "ax.set_xlabel(\"log(preço)\")\n",
        "ax.set_ylabel(\"Densidade\")\n",
        "ax.set_title(\"KDE com diferentes escolhas de bandwidth\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- O método com maior log-verossimilhança costuma ser o MLKDE (tabela acima). Ele premia curvas que tornam os dados observados mais prováveis.\n",
        "- As curvas são parecidas, mas **LSCV** pode suavizar demais e o **Plug-in** tende a ser conservador; o MLKDE segue melhor os picos reais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "point_densities = kde_density(log_prices, log_prices, h_mlkde)\n",
        "limiar = np.percentile(point_densities, 1)\n",
        "clean_df[\"densidade_mlkde\"] = point_densities\n",
        "clean_df[\"outlier\"] = np.where(point_densities < limiar, \"Outlier\", \"Faixa típica\")\n",
        "\n",
        "outliers = clean_df.sort_values(\"densidade_mlkde\").head(8)[[\"price\", \"log_price\", \"densidade_mlkde\", \"outlier\"]]\n",
        "faixa_baixa, faixa_alta = np.percentile(clean_df[\"price\"], [5, 95])\n",
        "\n",
        "outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.hist(clean_df[\"price\"], bins=50, color=\"lightgray\", edgecolor=\"white\")\n",
        "ax.axvspan(faixa_baixa, faixa_alta, color=\"mediumseagreen\", alpha=0.2, label=\"Faixa típica\")\n",
        "out_df = clean_df[clean_df[\"outlier\"] == \"Outlier\"]\n",
        "ax.scatter(out_df[\"price\"], np.full(len(out_df), 0.0005), color=\"crimson\", label=\"Outliers\", zorder=3)\n",
        "ax.set_xlabel(\"Preço por noite (EUR)\")\n",
        "ax.set_ylabel(\"Frequência\")\n",
        "ax.set_title(\"Preços originais com outliers destacados\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.scatter(clean_df[\"log_price\"], clean_df[\"densidade_mlkde\"], alpha=0.4, color=\"steelblue\", label=\"Anúncios\")\n",
        "ax.axhline(limiar, color=\"crimson\", linestyle=\"--\", label=\"Limiar (1º percentil)\")\n",
        "ax.scatter(out_df[\"log_price\"], out_df[\"densidade_mlkde\"], color=\"crimson\", label=\"Outliers\", zorder=3)\n",
        "ax.set_xlabel(\"log(preço)\")\n",
        "ax.set_ylabel(\"Densidade estimada\")\n",
        "ax.set_title(\"Densidade MLKDE por anúncio\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outliers aparecem nas duas caudas: anúncios muito baratos (possíveis promoções ou erros) e anúncios muito caros (ofertas premium ou preços fora do padrão). Eles ficam em regiões de **densidade muito baixa** segundo o KDE."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}