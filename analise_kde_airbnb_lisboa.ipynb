{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b362030b",
   "metadata": {},
   "source": [
    "# Estimação de Densidade por Kernel e Detecção de Outliers em Preços do Airbnb em Lisboa\n",
    "\n",
    "## Objetivo\n",
    "Este notebook estima a distribuição dos preços de acomodações do Airbnb em Lisboa usando **Kernel Density Estimation (KDE)** com kernel Gaussiano. A largura de banda é escolhida por **máxima verossimilhança leave-one-out (MLKDE)** e a densidade resultante é utilizada para identificar preços improváveis (outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf09bd",
   "metadata": {},
   "source": [
    "## 1. Título e objetivo\n",
    "Este estudo busca:\n",
    "- Estimar a densidade dos preços usando KDE com kernel Gaussiano.\n",
    "- Escolher a largura de banda (bandwidth) que maximiza a log-verossimilhança leave-one-out (MLKDE).\n",
    "- Usar a densidade estimada para destacar preços com baixa probabilidade (outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2d329",
   "metadata": {},
   "source": [
    "## 2. Importação de bibliotecas\n",
    "Carregamos as bibliotecas necessárias para manipulação de dados, cálculo numérico e visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f654329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import io\n",
    "import re\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff2d29",
   "metadata": {},
   "source": [
    "## 3. Carregamento e preparação dos dados\n",
    "O conjunto de dados é o `listings.csv` do **Inside Airbnb** (Lisboa). O notebook baixa automaticamente a versão mais recente disponível no site e salva como `data/listings_lisboa.csv` se o arquivo ainda não existir localmente. A análise usa apenas a coluna de preços (`price`).\n",
    "\n",
    "Passos de limpeza:\n",
    "1. Remover linhas sem preço.\n",
    "2. Converter strings de preço (por exemplo, `\"$120.00\"`) para valores numéricos.\n",
    "3. Filtrar preços não positivos.\n",
    "4. Criar `log_price = log(preço)`, o que reduz a influência de caudas longas e facilita a modelagem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815de6c2",
   "metadata": {},
   "source": [
    "### Download automático do dataset\n",
    "A função abaixo consulta `http://insideairbnb.com/get-the-data/` para encontrar o link mais recente de Lisboa, baixa o arquivo `listings.csv.gz`, descompacta e salva em `data/listings_lisboa.csv`. Se o arquivo já existir, o download é pulado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c16bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_latest_lisbon_listing(destination: Path) -> Path:\n",
    "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if destination.exists():\n",
    "        print(f\"Arquivo já encontrado em {destination}. Usando versão local.\")\n",
    "        return destination\n",
    "\n",
    "    index_url = \"http://insideairbnb.com/get-the-data/\"\n",
    "    with urllib.request.urlopen(index_url, timeout=15) as resp:\n",
    "        html = resp.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    match = re.search(\n",
    "        r\"https://data\\.insideairbnb\\.com/portugal/lisbon/lisbon/[0-9-]+/data/listings\\.csv\\.gz\",\n",
    "        html,\n",
    "    )\n",
    "    if not match:\n",
    "        raise RuntimeError(\"Não foi possível localizar o link de Lisboa no Inside Airbnb.\")\n",
    "\n",
    "    download_url = match.group(0)\n",
    "    request = urllib.request.Request(download_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    with urllib.request.urlopen(request, timeout=60) as resp:\n",
    "        compressed_bytes = io.BytesIO(resp.read())\n",
    "\n",
    "    with gzip.open(compressed_bytes, \"rt\", encoding=\"utf-8\") as gz, destination.open(\"w\", encoding=\"utf-8\") as out:\n",
    "        shutil.copyfileobj(gz, out)\n",
    "\n",
    "    print(f\"Arquivo baixado de {download_url}\")\n",
    "    print(f\"Salvo como {destination}\")\n",
    "    return destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7234ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/listings_lisboa.csv\")\n",
    "try:\n",
    "    download_latest_lisbon_listing(data_path)\n",
    "except Exception as exc:\n",
    "    raise RuntimeError(\n",
    "        \"Não foi possível baixar o dataset automaticamente. Baixe o listings.csv de Lisboa no Inside Airbnb e salve como data/listings_lisboa.csv.\"\n",
    "    ) from exc\n",
    "\n",
    "# Leitura e cópia do conjunto de dados original\n",
    "raw_df = pd.read_csv(data_path)\n",
    "if \"price\" not in raw_df.columns:\n",
    "    raise KeyError(\"A coluna 'price' não foi encontrada no arquivo fornecido.\")\n",
    "\n",
    "# Limpeza da coluna de preço\n",
    "prices = (\n",
    "    raw_df[\"price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"[^0-9,\\.]\", \"\", regex=True)  # remove símbolos monetários e outros caracteres\n",
    "    .str.replace(\",\", \"\", regex=False)  # remove separadores de milhar\n",
    ")\n",
    "prices = pd.to_numeric(prices, errors=\"coerce\")\n",
    "\n",
    "clean_df = raw_df.copy()\n",
    "clean_df[\"price\"] = prices\n",
    "clean_df = clean_df.dropna(subset=[\"price\"]).copy()\n",
    "clean_df = clean_df[clean_df[\"price\"] > 0].copy()\n",
    "clean_df[\"log_price\"] = np.log(clean_df[\"price\"])\n",
    "clean_df = clean_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Total de entradas após limpeza: {len(clean_df)}\")\n",
    "clean_df[[\"price\", \"log_price\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34220d10",
   "metadata": {},
   "source": [
    "## 4. Análise exploratória simples\n",
    "A seguir mostramos estatísticas descritivas e histogramas para `price` e `log_price`, destacando assimetria e caudas longas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "estatisticas = clean_df[[\"price\", \"log_price\"]].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "estatisticas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].hist(clean_df[\"price\"], bins=40, color=\"#4c72b0\", edgecolor=\"black\")\n",
    "axes[0].set_title(\"Histograma de price\")\n",
    "axes[0].set_xlabel(\"Preço\")\n",
    "axes[0].set_ylabel(\"Frequência\")\n",
    "\n",
    "axes[1].hist(clean_df[\"log_price\"], bins=40, color=\"#55a868\", edgecolor=\"black\")\n",
    "axes[1].set_title(\"Histograma de log_price\")\n",
    "axes[1].set_xlabel(\"log(preço)\")\n",
    "axes[1].set_ylabel(\"Frequência\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16f366",
   "metadata": {},
   "source": [
    "## 5. Implementação do KDE e do MLKDE\n",
    "\n",
    "**Kernel Density Estimation (KDE)** aproxima a função densidade de probabilidade dos dados. Para cada ponto de avaliação \\(x\\), a estimativa é dada por:\n",
    "\n",
    "\\[\\hat{f}(x) = \f",
    "rac{1}{n h} \\sum_{i=1}^{n} K\\left( \f",
    "rac{x - x_i}{h} \r",
    "ight)\\]\n",
    "\n",
    "- \\(K\\) é o kernel Gaussiano (simétrico, suave e com integral 1).\n",
    "- \\(h\\) (bandwidth) controla a suavização: valores pequenos produzem curvas muito onduladas; valores grandes podem esconder detalhes.\n",
    "\n",
    "Para escolher \\(h\\), usamos **máxima verossimilhança leave-one-out (MLKDE)**:\n",
    "- Para cada \\(x_i\\), calculamos \\(\\hat{f}_{-i}(x_i)\\) excluindo o próprio ponto.\n",
    "- Somamos \\(\\log(\\hat{f}_{-i}(x_i))\\) para obter a log-verossimilhança.\n",
    "- O \\(h\\) ótimo maximiza essa soma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Kernel Gaussiano padrão.\"\"\"\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * u ** 2)\n",
    "\n",
    "\n",
    "def kde_density(x_grid: np.ndarray, data: np.ndarray, bandwidth: float) -> np.ndarray:\n",
    "    \"\"\"KDE univariado com kernel Gaussiano.\"\"\"\n",
    "    n = data.shape[0]\n",
    "    scaled_diff = (x_grid[:, None] - data[None, :]) / bandwidth\n",
    "    kernel_vals = gaussian_kernel(scaled_diff)\n",
    "    density = kernel_vals.mean(axis=1) / bandwidth\n",
    "    return density\n",
    "\n",
    "\n",
    "def loo_log_likelihood(data: np.ndarray, bandwidth: float) -> float:\n",
    "    \"\"\"Log-verossimilhança leave-one-out para um bandwidth dado.\"\"\"\n",
    "    n = data.shape[0]\n",
    "    if bandwidth <= 0:\n",
    "        return -np.inf\n",
    "    scaled_diff = (data[:, None] - data[None, :]) / bandwidth\n",
    "    kernel_vals = gaussian_kernel(scaled_diff)\n",
    "    np.fill_diagonal(kernel_vals, 0.0)\n",
    "    density_i = kernel_vals.sum(axis=1) / ((n - 1) * bandwidth)\n",
    "    density_i = np.maximum(density_i, 1e-12)  # evita log(0)\n",
    "    return float(np.sum(np.log(density_i)))\n",
    "\n",
    "\n",
    "log_prices = clean_df[\"log_price\"].to_numpy()\n",
    "std_log = np.std(log_prices, ddof=1) if len(log_prices) > 1 else 1.0\n",
    "\n",
    "# Intervalo de busca para h\n",
    "h_min = max(0.05, 0.1 * std_log)\n",
    "h_max = max(h_min * 2, 1.5 * std_log)\n",
    "h_values = np.linspace(h_min, h_max, 40)\n",
    "\n",
    "log_liks = [loo_log_likelihood(log_prices, h) for h in h_values]\n",
    "best_idx = int(np.argmax(log_liks))\n",
    "best_h = h_values[best_idx]\n",
    "\n",
    "print(f\"Bandwidth ótimo (MLKDE): {best_h:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d727f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(h_values, log_liks, marker=\"o\", color=\"#4c72b0\")\n",
    "ax.axvline(best_h, color=\"#c44e52\", linestyle=\"--\", label=f\"h ótimo = {best_h:.4f}\")\n",
    "ax.set_xlabel(\"Bandwidth (h)\")\n",
    "ax.set_ylabel(\"Log-verossimilhança LOO\")\n",
    "ax.set_title(\"Busca do bandwidth por MLKDE\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a91357",
   "metadata": {},
   "source": [
    "O valor de \\(h\\) que maximiza a log-verossimilhança oferece o melhor equilíbrio entre suavização e fidelidade aos dados segundo o critério LOO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d574390",
   "metadata": {},
   "source": [
    "## 6. KDE final com o bandwidth ótimo\n",
    "Usamos o \\(h\\) selecionado para estimar a densidade em um grid ao redor de `log_price` e comparamos a curva KDE com o histograma (densidade empírica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782da978",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.5 * std_log if std_log > 0 else 0.5\n",
    "x_grid = np.linspace(log_prices.min() - margin, log_prices.max() + margin, 200)\n",
    "density_grid = kde_density(x_grid, log_prices, best_h)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(clean_df[\"log_price\"], bins=40, density=True, color=\"#c7e9c0\", edgecolor=\"#4c72b0\", alpha=0.8, label=\"Histograma (densidade)\")\n",
    "ax.plot(x_grid, density_grid, color=\"#1b9e77\", linewidth=2.5, label=\"KDE com h ótimo\")\n",
    "ax.set_xlabel(\"log(preço)\")\n",
    "ax.set_ylabel(\"Densidade\")\n",
    "ax.set_title(\"Densidade estimada vs. histograma\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7808bf",
   "metadata": {},
   "source": [
    "A curva KDE suavizada acompanha a distribuição observada de `log_price`, revelando a forma geral da densidade e destacando possíveis regiões com menor probabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641c074",
   "metadata": {},
   "source": [
    "## 7. Detecção de outliers com base na densidade\n",
    "Pontos com densidade estimada muito baixa indicam preços improváveis. Vamos usar um critério configurável: marcar como outlier qualquer observação cuja densidade estimada esteja abaixo de um percentil definido (por padrão, 1%). Isso deixa claro o limiar usado e permite ajustar a sensibilidade da detecção.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentil_outlier = 1.0  # percentil usado para definir o limiar de densidade\n",
    "\n",
    "densidades_nos_pontos = kde_density(log_prices, log_prices, best_h)\n",
    "limiar = np.percentile(densidades_nos_pontos, percentil_outlier)\n",
    "clean_df[\"kde_density\"] = densidades_nos_pontos\n",
    "clean_df[\"outlier\"] = clean_df[\"kde_density\"] < limiar\n",
    "\n",
    "n_outliers = int(clean_df[\"outlier\"].sum())\n",
    "proporcao_outliers = n_outliers / len(clean_df) if len(clean_df) > 0 else 0.0\n",
    "\n",
    "resumo_outliers = clean_df[[\"price\", \"log_price\", \"kde_density\", \"outlier\"]].copy()\n",
    "resumo_outliers_ordenado = resumo_outliers.sort_values(\"kde_density\", ascending=True)\n",
    "\n",
    "print(f\"Limiar de densidade (percentil {percentil_outlier}%): {limiar:.6f}\")\n",
    "print(f\"Total de outliers: {n_outliers}\")\n",
    "print(f\"Proporção de outliers: {proporcao_outliers:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0824de3",
   "metadata": {},
   "source": [
    "Chamamos de **outliers** as acomodações que caem na região de densidade mais baixa da curva — por padrão, os **1% de preços menos prováveis segundo o modelo**. Esse critério usa o percentil `percentil_outlier` para definir o limiar de densidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95002a",
   "metadata": {},
   "source": [
    "Estas são as observações mais improváveis segundo a densidade estimada (ordenadas da menor para a maior densidade). A tabela ajuda a enxergar os preços que ficam na cauda da distribuição — os 'preços mais estranhos' para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955af89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_outliers = resumo_outliers_ordenado.head(20)\n",
    "display(top_outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef03dee",
   "metadata": {},
   "source": [
    "### Visualização dos outliers\n",
    "Os gráficos a seguir destacam onde os outliers aparecem na escala de preços original e na relação entre o preço e a densidade estimada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a01400",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "contagens, bins, _ = ax.hist(\n",
    "    clean_df[\"price\"], bins=50, density=True, color=\"#d0e1f9\", edgecolor=\"#4c72b0\", alpha=0.85, label=\"Distribuição de preços\"\n",
    ")\n",
    "\n",
    "p5, p95 = np.percentile(clean_df[\"price\"], [5, 95]) if len(clean_df) > 0 else (0, 0)\n",
    "ax.axvspan(p5, p95, color=\"#b2df8a\", alpha=0.3, label=\"Faixa típica (5% a 95%)\")\n",
    "\n",
    "outlier_prices = clean_df.loc[clean_df[\"outlier\"], \"price\"]\n",
    "if not outlier_prices.empty:\n",
    "    y_max = contagens.max() if len(contagens) else 0.0\n",
    "    y_offset = -0.02 * y_max if y_max > 0 else -0.001\n",
    "    ax.scatter(\n",
    "        outlier_prices,\n",
    "        np.full_like(outlier_prices, y_offset),\n",
    "        color=\"#e84a5f\",\n",
    "        alpha=0.9,\n",
    "        marker=\"v\",\n",
    "        s=50,\n",
    "        label=\"Outliers (densidade < limiar)\"\n",
    "    )\n",
    "    ax.set_ylim(y_offset * 1.2, ax.get_ylim()[1] * 1.05)\n",
    "\n",
    "ax.set_xlabel(\"Preço (euros)\")\n",
    "ax.set_ylabel(\"Densidade\")\n",
    "ax.set_title(\"Distribuição dos preços com outliers destacados\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd26c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = np.where(clean_df[\"outlier\"], \"#e84a5f\", \"#4c72b0\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(\n",
    "    clean_df[\"price\"],\n",
    "    clean_df[\"kde_density\"],\n",
    "    c=cores,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=0.6,\n",
    "    label=\"Observações\"\n",
    ")\n",
    "ax.axhline(limiar, color=\"#e84a5f\", linestyle=\"--\", linewidth=1.5, label=f\"Limiar de densidade ({percentil_outlier}% mais baixo)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Preço (escala log)\")\n",
    "ax.set_ylabel(\"Densidade estimada\")\n",
    "ax.set_title(\"Preços vs. densidade — pontos abaixo da linha são outliers\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "1faeb4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Por que esses pontos são outliers?\n",
    "- A maior parte das acomodações concentra-se em uma faixa típica de preços.\n",
    "- Os pontos marcados como outliers ficam na ponta da cauda da distribuição: preços muito baixos ou muito altos em relação à maioria.\n",
    "- Eles podem refletir acomodações de luxo, anúncios com erro de preço ou estratégias agressivas de precificação — situações raras e pouco prováveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd73a2d",
   "metadata": {},
   "source": [
    "## 8. Comparação do bandwidth por máxima verossimilhança com regras clássicas\n",
    "Vamos comparar o bandwidth ótimo obtido pelo MLKDE com duas regras clássicas para KDE univariado: Silverman e Scott. Além de listar cada \\(h\\), avaliamos a log-verossimilhança leave-one-out para ver qual escolha se ajusta melhor aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e21d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(log_prices)\n",
    "iqr_log = np.subtract(*np.percentile(log_prices, [75, 25])) if n > 0 else 0.0\n",
    "sigma_log = np.std(log_prices, ddof=1) if n > 1 else 0.0\n",
    "\n",
    "h_silverman = 0.9 * min(sigma_log, iqr_log / 1.34) * n ** (-1 / 5) if n > 1 else np.nan\n",
    "h_scott = sigma_log * n ** (-1 / 5) if n > 1 else np.nan\n",
    "\n",
    "h_candidates = {\"MLKDE\": best_h, \"Silverman\": h_silverman, \"Scott\": h_scott}\n",
    "\n",
    "\n",
    "def loglik_loo(h):\n",
    "    return loo_log_likelihood(log_prices, h) if np.isfinite(h) else -np.inf\n",
    "\n",
    "comparacao_h = pd.DataFrame({\n",
    "    \"metodo\": list(h_candidates.keys()),\n",
    "    \"h\": list(h_candidates.values()),\n",
    "    \"log_verossimilhanca_loo\": [loglik_loo(h) for h in h_candidates.values()]\n",
    "}).sort_values(\"log_verossimilhanca_loo\", ascending=False)\n",
    "\n",
    "comparacao_h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13d9b9",
   "metadata": {},
   "source": [
    "A tabela resume as larguras de banda testadas e a log-verossimilhança leave-one-out de cada uma (quanto maior, melhor). O gráfico compara as curvas KDE resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(clean_df[\"log_price\"], bins=40, density=True, color=\"#e0f3db\", edgecolor=\"#4c72b0\", alpha=0.7, label=\"Histograma de log(preço)\")\n",
    "\n",
    "cores_metodos = {\"MLKDE\": \"#1b9e77\", \"Silverman\": \"#d95f02\", \"Scott\": \"#7570b3\"}\n",
    "for metodo, h in h_candidates.items():\n",
    "    if np.isfinite(h):\n",
    "        dens = kde_density(x_grid, log_prices, h)\n",
    "        ax.plot(x_grid, dens, color=cores_metodos.get(metodo, \"black\"), linewidth=2, label=f\"{metodo} (h = {h:.4f})\")\n",
    "ax.set_xlabel(\"log(preço)\")\n",
    "ax.set_ylabel(\"Densidade\")\n",
    "ax.set_title(\"Curvas KDE para diferentes larguras de banda\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e098b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_sets = {}\n",
    "for metodo, h in h_candidates.items():\n",
    "    if np.isfinite(h):\n",
    "        densidades = kde_density(log_prices, log_prices, h)\n",
    "        limite = np.percentile(densidades, percentil_outlier)\n",
    "        indices_outliers = set(clean_df.index[densidades < limite])\n",
    "        outlier_sets[metodo] = indices_outliers\n",
    "\n",
    "resumo_outliers_metodos = pd.DataFrame([\n",
    "    {\"metodo\": metodo, \"qtd_outliers\": len(indices), \"outliers_com_MLKDE\": len(indices & outlier_sets.get(\"MLKDE\", set()))}\n",
    "    for metodo, indices in outlier_sets.items()\n",
    "]) if outlier_sets else pd.DataFrame()\n",
    "\n",
    "outliers_comuns_todos = len(set.intersection(*outlier_sets.values())) if len(outlier_sets) > 1 else (len(next(iter(outlier_sets.values()))) if outlier_sets else 0)\n",
    "\n",
    "display(resumo_outliers_metodos)\n",
    "print(f\"Outliers comuns a todos os métodos: {outliers_comuns_todos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca371de",
   "metadata": {},
   "source": [
    "Os valores de log-verossimilhança indicam qual largura de banda se ajusta melhor aos dados: o método no topo da tabela maximiza essa métrica e tende a reproduzir melhor a forma empírica da distribuição. As curvas geralmente ficam parecidas, mas pequenas diferenças de suavização aparecem nas caudas. Bandwidths menores destacam mais picos e podem gerar mais outliers; bandwidths maiores suavizam a curva e escondem alguns extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777a182",
   "metadata": {},
   "source": [
    "### Quem performou melhor?\n",
    "- O método listado em primeiro lugar na tabela tem a maior log-verossimilhança leave-one-out, ou seja, ele explica melhor os dados segundo esse critério.\n",
    "- Visualmente, as curvas diferem pouco no centro, mas Silverman/Scott podem suavizar mais as caudas, enquanto o MLKDE tende a seguir de perto os picos observados.\n",
    "- Dizer que o MLKDE é \"melhor\" significa que ele maximiza a verossimilhança; em contextos exploratórios, regras clássicas ainda podem ser suficientes quando simplicidade e rapidez são prioridades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7e172",
   "metadata": {},
   "source": [
    "## 9. Conclusão\n",
    "- Estimamos a densidade dos preços do Airbnb em Lisboa via KDE com kernel Gaussiano.\n",
    "- O bandwidth escolhido por máxima verossimilhança leave-one-out (MLKDE) superou as regras clássicas na log-verossimilhança e guiou a marcação de outliers.\n",
    "- A densidade estimada identificou outliers como os \"1% mais improváveis\" da distribuição: preços muito fora do padrão da maioria dos anúncios.\n",
    "- Um bandwidth maior tenderia a suavizar a curva e reduzir a quantidade de outliers sinalizados; um bandwidth menor realçaria picos e poderia aumentar a detecção de pontos extremos.\n",
    "- A transformação logarítmica estabiliza a variabilidade e facilita a visualização de preços incomuns; análises futuras podem segmentar por bairro, tipo de acomodação ou adicionar variáveis para critérios multivariados."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
