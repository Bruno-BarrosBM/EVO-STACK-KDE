{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# EVO-STACK-KDE - Pipeline completo em uma única célula para execução no Colab\n",
        "import json\n",
        "import random\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Callable, Iterable, List, Optional, Sequence, Tuple\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from deap import base, creator, tools\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.special import logsumexp\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Utilidades gerais e preparação\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def log_step(message: str) -> None:\n",
        "    print(f\"[EVO-STACK-KDE] {message}\", flush=True)\n",
        "\n",
        "\n",
        "def seed_everything(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    try:\n",
        "        import torch  # type: ignore\n",
        "\n",
        "        torch.manual_seed(seed)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Manipulação dos dados\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "@dataclass\n",
        "class DataSplits:\n",
        "    X_train: np.ndarray\n",
        "    X_val: np.ndarray\n",
        "    X_test: np.ndarray\n",
        "    scaler: StandardScaler\n",
        "\n",
        "    def shapes(self) -> Tuple[int, int, int]:\n",
        "        return self.X_train.shape[0], self.X_val.shape[0], self.X_test.shape[0]\n",
        "\n",
        "    def dimension(self) -> int:\n",
        "        return self.X_train.shape[1]\n",
        "\n",
        "\n",
        "def load_wine_red(csv_path: str | Path) -> pd.DataFrame:\n",
        "    csv_path = Path(csv_path)\n",
        "    if not csv_path.exists():\n",
        "        raise FileNotFoundError(f\"CSV não encontrado: {csv_path}\")\n",
        "    try:\n",
        "        return pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
        "    except Exception:\n",
        "        return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "def split_and_scale(\n",
        "    df: pd.DataFrame,\n",
        "    test_size: float = 0.15,\n",
        "    val_size: float = 0.15,\n",
        "    seed: int = 42,\n",
        ") -> DataSplits:\n",
        "    if \"quality\" in df.columns:\n",
        "        df = df.drop(columns=[\"quality\"])\n",
        "    X = df.values.astype(float)\n",
        "    X_train, X_temp = train_test_split(\n",
        "        X,\n",
        "        test_size=test_size + val_size,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    relative_val_size = val_size / (test_size + val_size)\n",
        "    X_val, X_test = train_test_split(\n",
        "        X_temp,\n",
        "        test_size=1 - relative_val_size,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    return DataSplits(X_train_scaled, X_val_scaled, X_test_scaled, scaler)\n",
        "\n",
        "\n",
        "def persist_splits(splits: DataSplits, out_dir: str | Path) -> None:\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    np.savez(\n",
        "        out_dir / \"splits.npz\",\n",
        "        X_train=splits.X_train,\n",
        "        X_val=splits.X_val,\n",
        "        X_test=splits.X_test,\n",
        "    )\n",
        "    meta = {\n",
        "        \"n_train\": int(splits.X_train.shape[0]),\n",
        "        \"n_val\": int(splits.X_val.shape[0]),\n",
        "        \"n_test\": int(splits.X_test.shape[0]),\n",
        "        \"dimension\": int(splits.dimension()),\n",
        "        \"scaler_mean\": splits.scaler.mean_.tolist(),\n",
        "        \"scaler_scale\": splits.scaler.scale_.tolist(),\n",
        "    }\n",
        "    with open(out_dir / \"meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Modelos KDE\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def scott_bandwidth(X: np.ndarray) -> float:\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"Array deve ser 2D\")\n",
        "    n, d = X.shape\n",
        "    if n <= 0 or d <= 0:\n",
        "        raise ValueError(\"Dimensões inválidas para KDE\")\n",
        "    return np.power(n, -1.0 / (d + 4))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class KDEExpert:\n",
        "    feature_mask: Optional[np.ndarray]\n",
        "    alpha: float = 1.0\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        if self.feature_mask is not None:\n",
        "            mask = np.asarray(self.feature_mask, dtype=bool)\n",
        "            if mask.ndim != 1:\n",
        "                raise ValueError(\"feature_mask deve ser 1D\")\n",
        "            if not mask.any():\n",
        "                raise ValueError(\"feature_mask deve selecionar ao menos uma feature\")\n",
        "            self.feature_mask = mask\n",
        "        self.model: Optional[KernelDensity] = None\n",
        "\n",
        "    def _apply_mask(self, X: np.ndarray) -> np.ndarray:\n",
        "        if self.feature_mask is None:\n",
        "            return X\n",
        "        return X[:, self.feature_mask]\n",
        "\n",
        "    def fit(self, X: np.ndarray) -> \"KDEExpert\":\n",
        "        subspace = self._apply_mask(X)\n",
        "        h0 = scott_bandwidth(subspace)\n",
        "        bandwidth = max(h0 * float(self.alpha), 1e-6)\n",
        "        self.model = KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth)\n",
        "        self.model.fit(subspace)\n",
        "        return self\n",
        "\n",
        "    def logpdf(self, X: np.ndarray) -> np.ndarray:\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"KDEExpert precisa ser treinado antes de logpdf\")\n",
        "        subspace = self._apply_mask(X)\n",
        "        return self.model.score_samples(subspace)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class KDEEnsemble:\n",
        "    experts: Sequence[KDEExpert]\n",
        "    weight_logits: np.ndarray\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        if len(self.experts) == 0:\n",
        "            raise ValueError(\"KDEEnsemble requer pelo menos um expert\")\n",
        "        self.weight_logits = np.asarray(self.weight_logits, dtype=float)\n",
        "        if self.weight_logits.shape != (len(self.experts),):\n",
        "            raise ValueError(\"weight_logits deve ter o mesmo tamanho de experts\")\n",
        "        self._weights = self._softmax(self.weight_logits)\n",
        "\n",
        "    @staticmethod\n",
        "    def _softmax(z: np.ndarray) -> np.ndarray:\n",
        "        z = np.asarray(z, dtype=float)\n",
        "        z = z - np.max(z)\n",
        "        exp_z = np.exp(z)\n",
        "        return exp_z / np.sum(exp_z)\n",
        "\n",
        "    @property\n",
        "    def weights(self) -> np.ndarray:\n",
        "        return self._weights\n",
        "\n",
        "    def fit(self, X: np.ndarray) -> \"KDEEnsemble\":\n",
        "        for expert in self.experts:\n",
        "            expert.fit(X)\n",
        "        return self\n",
        "\n",
        "    def logpdf(self, X: np.ndarray) -> np.ndarray:\n",
        "        logps = np.column_stack([expert.logpdf(X) for expert in self.experts])\n",
        "        log_weights = np.log(self._weights)\n",
        "        return logsumexp(logps + log_weights, axis=1)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Genoma evolutivo (configurações do ensemble)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "@dataclass\n",
        "class ExpertConfig:\n",
        "    alpha: float\n",
        "    feature_mask: np.ndarray\n",
        "\n",
        "    def to_jsonable(self) -> dict:\n",
        "        return {\n",
        "            \"alpha\": float(self.alpha),\n",
        "            \"feature_mask\": self.feature_mask.astype(int).tolist(),\n",
        "        }\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    weight_logits: np.ndarray\n",
        "    experts: List[ExpertConfig] = field(default_factory=list)\n",
        "\n",
        "    def to_jsonable(self) -> dict:\n",
        "        return {\n",
        "            \"weight_logits\": self.weight_logits.tolist(),\n",
        "            \"experts\": [expert.to_jsonable() for expert in self.experts],\n",
        "        }\n",
        "\n",
        "\n",
        "def random_mask(\n",
        "    d: int,\n",
        "    rng: np.random.Generator,\n",
        "    keep_frac_range: Sequence[float] = (0.6, 0.8),\n",
        ") -> np.ndarray:\n",
        "    if d <= 0:\n",
        "        raise ValueError(\"d deve ser positivo\")\n",
        "    low, high = keep_frac_range\n",
        "    keep_frac = rng.uniform(low, high)\n",
        "    n_keep = max(1, int(round(keep_frac * d)))\n",
        "    mask = np.zeros(d, dtype=bool)\n",
        "    idx = rng.choice(d, size=n_keep, replace=False)\n",
        "    mask[idx] = True\n",
        "    return mask\n",
        "\n",
        "\n",
        "def random_model_config(d: int, rng: np.random.Generator, m: int = 5) -> ModelConfig:\n",
        "    experts = []\n",
        "    for _ in range(m):\n",
        "        alpha = float(rng.uniform(0.5, 1.5))\n",
        "        mask = random_mask(d, rng)\n",
        "        experts.append(ExpertConfig(alpha=alpha, feature_mask=mask))\n",
        "    weight_logits = rng.normal(0.0, 1.0, size=m)\n",
        "    return ModelConfig(weight_logits=weight_logits, experts=experts)\n",
        "\n",
        "\n",
        "def decode_to_model(config: ModelConfig) -> Callable[[], KDEEnsemble]:\n",
        "    def factory() -> KDEEnsemble:\n",
        "        experts = [\n",
        "            KDEExpert(feature_mask=cfg.feature_mask.copy(), alpha=cfg.alpha)\n",
        "            for cfg in config.experts\n",
        "        ]\n",
        "        return KDEEnsemble(\n",
        "            experts=experts,\n",
        "            weight_logits=np.array(config.weight_logits, dtype=float),\n",
        "        )\n",
        "\n",
        "    return factory\n",
        "\n",
        "\n",
        "def model_config_from_jsonable(data: dict) -> ModelConfig:\n",
        "    experts = [\n",
        "        ExpertConfig(\n",
        "            alpha=float(exp[\"alpha\"]),\n",
        "            feature_mask=np.array(exp[\"feature_mask\"], dtype=bool),\n",
        "        )\n",
        "        for exp in data[\"experts\"]\n",
        "    ]\n",
        "    weight_logits = np.array(data[\"weight_logits\"], dtype=float)\n",
        "    return ModelConfig(weight_logits=weight_logits, experts=experts)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Métricas de avaliação\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def _ensure_2d(X: np.ndarray) -> np.ndarray:\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"Esperado array 2D\")\n",
        "    return X\n",
        "\n",
        "\n",
        "def nll_kfold(\n",
        "    model_factory: Callable[[], KDEEnsemble],\n",
        "    X: np.ndarray,\n",
        "    k: int = 3,\n",
        "    seed: int = 42,\n",
        ") -> float:\n",
        "    X = _ensure_2d(np.asarray(X, dtype=float))\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
        "    nlls = []\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        model = model_factory()\n",
        "        model.fit(X[train_idx])\n",
        "        logp = model.logpdf(X[val_idx])\n",
        "        nlls.append(float(-np.mean(logp)))\n",
        "    return float(np.mean(nlls))\n",
        "\n",
        "\n",
        "def stability_bootstrap(\n",
        "    model_factory: Callable[[], KDEEnsemble],\n",
        "    X: np.ndarray,\n",
        "    B: int = 10,\n",
        "    k: int = 3,\n",
        "    seed: int = 42,\n",
        ") -> float:\n",
        "    X = _ensure_2d(np.asarray(X, dtype=float))\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = X.shape[0]\n",
        "    scores = []\n",
        "    for _ in range(B):\n",
        "        sample_idx = rng.integers(0, n, size=n)\n",
        "        X_boot = X[sample_idx]\n",
        "        scores.append(nll_kfold(model_factory, X_boot, k=k, seed=seed))\n",
        "    return float(np.std(scores))\n",
        "\n",
        "\n",
        "def _softmax(z: Sequence[float]) -> np.ndarray:\n",
        "    z = np.asarray(z, dtype=float)\n",
        "    z = z - np.max(z)\n",
        "    exp_z = np.exp(z)\n",
        "    return exp_z / np.sum(exp_z)\n",
        "\n",
        "\n",
        "def complexity(\n",
        "    config: ModelConfig,\n",
        "    n: int,\n",
        "    d: int,\n",
        "    lam_entropy: float = 0.0,\n",
        ") -> float:\n",
        "    if d <= 0:\n",
        "        raise ValueError(\"d deve ser positivo\")\n",
        "    base_factor = min(1.0, n / 2000.0)\n",
        "    complexities = []\n",
        "    for expert in config.experts:\n",
        "        mask = np.asarray(expert.feature_mask, dtype=bool)\n",
        "        if not mask.any():\n",
        "            raise ValueError(\"Máscara do expert deve selecionar ao menos uma feature\")\n",
        "        complexities.append(mask.sum() / d * base_factor)\n",
        "    mean_complexity = float(np.mean(complexities))\n",
        "    if lam_entropy > 0:\n",
        "        weights = _softmax(config.weight_logits)\n",
        "        entropy = -np.sum(weights * np.log(weights + 1e-12))\n",
        "        norm_entropy = entropy / np.log(len(weights))\n",
        "        mean_complexity += lam_entropy * float(norm_entropy)\n",
        "    return mean_complexity\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Rotinas de plotagem\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def plot_pareto_2d(pareto_fits: Iterable[Iterable[float]], out_png: str | Path) -> None:\n",
        "    data = np.array(list(pareto_fits), dtype=float)\n",
        "    if data.ndim != 2 or data.shape[1] < 3:\n",
        "        raise ValueError(\"pareto_fits deve fornecer triplas (f1, f2, f3)\")\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    axes[0].scatter(data[:, 0], data[:, 1], c=\"tab:blue\", alpha=0.7)\n",
        "    axes[0].set_xlabel(\"f1: NLL\")\n",
        "    axes[0].set_ylabel(\"f2: Estabilidade\")\n",
        "    axes[0].set_title(\"Pareto (f1 vs f2)\")\n",
        "    axes[1].scatter(data[:, 0], data[:, 2], c=\"tab:orange\", alpha=0.7)\n",
        "    axes[1].set_xlabel(\"f1: NLL\")\n",
        "    axes[1].set_ylabel(\"f3: Complexidade\")\n",
        "    axes[1].set_title(\"Pareto (f1 vs f3)\")\n",
        "    fig.tight_layout()\n",
        "    out_png = Path(out_png)\n",
        "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
        "    fig.savefig(out_png)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def plot_hist_neglogp_test(neg_logp: Iterable[float], out_png: str | Path) -> None:\n",
        "    values = np.array(list(neg_logp), dtype=float)\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    ax.hist(values, bins=20, color=\"tab:green\", alpha=0.8)\n",
        "    ax.set_xlabel(\"-log p(x)\")\n",
        "    ax.set_ylabel(\"Frequência\")\n",
        "    ax.set_title(\"Distribuição no conjunto de teste\")\n",
        "    fig.tight_layout()\n",
        "    out_png = Path(out_png)\n",
        "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
        "    fig.savefig(out_png)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Núcleo NSGA-II\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def _ensure_creators() -> None:\n",
        "    if \"FitnessMin3\" not in creator.__dict__:\n",
        "        creator.create(\"FitnessMin3\", base.Fitness, weights=(-1.0, -1.0, -1.0))\n",
        "    if \"Individual\" not in creator.__dict__:\n",
        "        creator.create(\"Individual\", ModelConfig, fitness=creator.FitnessMin3)\n",
        "\n",
        "\n",
        "def _clone_expert(expert: ExpertConfig) -> ExpertConfig:\n",
        "    return ExpertConfig(alpha=expert.alpha, feature_mask=expert.feature_mask.copy())\n",
        "\n",
        "\n",
        "def _clone_config(config: ModelConfig) -> ModelConfig:\n",
        "    return ModelConfig(\n",
        "        weight_logits=config.weight_logits.copy(),\n",
        "        experts=[_clone_expert(exp) for exp in config.experts],\n",
        "    )\n",
        "\n",
        "\n",
        "def _make_individual(config: ModelConfig) -> ModelConfig:\n",
        "    return creator.Individual(\n",
        "        weight_logits=config.weight_logits.copy(),\n",
        "        experts=[_clone_expert(e) for e in config.experts],\n",
        "    )\n",
        "\n",
        "\n",
        "def _crossover(\n",
        "    config_a: ModelConfig,\n",
        "    config_b: ModelConfig,\n",
        "    rng: np.random.Generator,\n",
        ") -> Tuple[ModelConfig, ModelConfig]:\n",
        "    m = len(config_a.experts)\n",
        "    point = rng.integers(1, m) if m > 1 else 0\n",
        "    experts1 = [\n",
        "        _clone_expert(exp) for exp in (config_a.experts[:point] + config_b.experts[point:])\n",
        "    ]\n",
        "    experts2 = [\n",
        "        _clone_expert(exp) for exp in (config_b.experts[:point] + config_a.experts[point:])\n",
        "    ]\n",
        "    blend = rng.uniform(0.25, 0.75)\n",
        "    logits1 = blend * config_a.weight_logits + (1.0 - blend) * config_b.weight_logits\n",
        "    logits2 = blend * config_b.weight_logits + (1.0 - blend) * config_a.weight_logits\n",
        "    return (\n",
        "        ModelConfig(weight_logits=logits1.copy(), experts=experts1),\n",
        "        ModelConfig(weight_logits=logits2.copy(), experts=experts2),\n",
        "    )\n",
        "\n",
        "\n",
        "def _mutate(config: ModelConfig, rng: np.random.Generator) -> ModelConfig:\n",
        "    mutated = _clone_config(config)\n",
        "    for expert in mutated.experts:\n",
        "        log_alpha = np.log(expert.alpha)\n",
        "        log_alpha += rng.normal(0.0, 0.15)\n",
        "        expert.alpha = float(np.clip(np.exp(log_alpha), 0.1, 5.0))\n",
        "        mask = expert.feature_mask.copy()\n",
        "        flip_prob = 1.0 / mask.size\n",
        "        flips = rng.random(mask.size) < flip_prob\n",
        "        mask = np.logical_xor(mask, flips)\n",
        "        if not mask.any():\n",
        "            mask[rng.integers(0, mask.size)] = True\n",
        "        expert.feature_mask = mask\n",
        "    mutated.weight_logits = (\n",
        "        mutated.weight_logits + rng.normal(0.0, 0.3, size=mutated.weight_logits.shape)\n",
        "    )\n",
        "    return mutated\n",
        "\n",
        "\n",
        "def run_nsga(\n",
        "    X: np.ndarray,\n",
        "    pop_size: int = 60,\n",
        "    n_gen: int = 40,\n",
        "    seed: int = 42,\n",
        "    kfold: int = 3,\n",
        "    bootstraps: int = 10,\n",
        "    outdir: str | Path = \"outputs\",\n",
        ") -> Tuple[List[dict], Path]:\n",
        "    _ensure_creators()\n",
        "    rng = np.random.default_rng(seed)\n",
        "    toolbox = base.Toolbox()\n",
        "    d = X.shape[1]\n",
        "\n",
        "    def init_individual() -> ModelConfig:\n",
        "        config = random_model_config(d, rng, m=5)\n",
        "        return _make_individual(config)\n",
        "\n",
        "    toolbox.register(\"individual\", init_individual)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "    def evaluate(individual: ModelConfig) -> Tuple[float, float, float]:\n",
        "        config = individual\n",
        "        factory = decode_to_model(config)\n",
        "        f1 = nll_kfold(factory, X, k=kfold, seed=seed)\n",
        "        f2 = stability_bootstrap(factory, X, B=bootstraps, k=kfold, seed=seed)\n",
        "        f3 = complexity(config, n=X.shape[0], d=d)\n",
        "        return f1, f2, f3\n",
        "\n",
        "    toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "    def mate(ind1: ModelConfig, ind2: ModelConfig) -> Tuple[ModelConfig, ModelConfig]:\n",
        "        child1, child2 = _crossover(ind1, ind2, rng)\n",
        "        return _make_individual(child1), _make_individual(child2)\n",
        "\n",
        "    def mutate(ind: ModelConfig) -> Tuple[ModelConfig]:\n",
        "        mutated = _mutate(ind, rng)\n",
        "        return (_make_individual(mutated),)\n",
        "\n",
        "    toolbox.register(\"mate\", mate)\n",
        "    toolbox.register(\"mutate\", mutate)\n",
        "    toolbox.register(\"select\", tools.selNSGA2)\n",
        "\n",
        "    pop = toolbox.population(n=pop_size)\n",
        "\n",
        "    for ind in tqdm(pop, desc=\"Avaliando população inicial\", unit=\"ind\"):\n",
        "        ind.fitness.values = toolbox.evaluate(ind)\n",
        "\n",
        "    pop = toolbox.select(pop, len(pop))\n",
        "\n",
        "    for gen in tqdm(range(1, n_gen + 1), desc=\"Evoluindo gerações\", unit=\"ger\"):\n",
        "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
        "        offspring = [_clone_config(ind) for ind in offspring]\n",
        "        for i in range(1, len(offspring), 2):\n",
        "            if rng.random() < 0.9:\n",
        "                child1, child2 = _crossover(offspring[i - 1], offspring[i], rng)\n",
        "                offspring[i - 1], offspring[i] = child1, child2\n",
        "        for i in range(len(offspring)):\n",
        "            if rng.random() < 0.4:\n",
        "                offspring[i] = _mutate(offspring[i], rng)\n",
        "        offspring = [_make_individual(cfg) for cfg in offspring]\n",
        "        for ind in tqdm(\n",
        "            offspring,\n",
        "            desc=f\"Geração {gen}: avaliando descendentes\",\n",
        "            unit=\"ind\",\n",
        "            leave=False,\n",
        "        ):\n",
        "            ind.fitness.values = toolbox.evaluate(ind)\n",
        "        pop = toolbox.select(pop + offspring, pop_size)\n",
        "\n",
        "    pareto_front = tools.sortNondominated(pop, k=len(pop), first_front_only=True)[0]\n",
        "    timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_dir = Path(outdir) / \"runs\" / timestamp\n",
        "    run_dir.mkdir(parents=True, exist_ok=True)\n",
        "    pareto_data: List[dict] = []\n",
        "    for ind in pareto_front:\n",
        "        pareto_data.append({\"config\": ind.to_jsonable(), \"fitness\": list(ind.fitness.values)})\n",
        "    with open(run_dir / \"pareto.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(pareto_data, f, indent=2)\n",
        "    return pareto_data, run_dir\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Pipeline completo\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def select_knee(pareto: List[dict]) -> dict:\n",
        "    fitness = np.array([entry[\"fitness\"] for entry in pareto], dtype=float)\n",
        "    mins = fitness.min(axis=0)\n",
        "    maxs = fitness.max(axis=0)\n",
        "    ranges = np.where(maxs - mins == 0, 1.0, maxs - mins)\n",
        "    normalized = (fitness - mins) / ranges\n",
        "    distances = np.linalg.norm(normalized, axis=1)\n",
        "    idx = int(np.argmin(distances))\n",
        "    return pareto[idx]\n",
        "\n",
        "\n",
        "def run_pipeline(\n",
        "    csv_path: str | Path,\n",
        "    seed: int = 42,\n",
        "    outdir: str | Path = \"outputs\",\n",
        "    pop: int = 60,\n",
        "    gens: int = 40,\n",
        "    kfold: int = 3,\n",
        "    bootstraps: int = 10,\n",
        ") -> dict:\n",
        "    log_step(\"Iniciando pipeline EVO-STACK-KDE\")\n",
        "    log_step(f\"Seed global definida como {seed}\")\n",
        "    seed_everything(seed)\n",
        "\n",
        "    log_step(f\"Carregando dados a partir de '{csv_path}'\")\n",
        "    data_df = load_wine_red(csv_path)\n",
        "    log_step(\"Dividindo dataset em treino/validação/teste e aplicando padronização\")\n",
        "    splits = split_and_scale(data_df, seed=seed)\n",
        "    log_step(\"Persistindo divisões processadas em 'data/processed'\")\n",
        "    persist_splits(splits, Path(\"data/processed\"))\n",
        "\n",
        "    log_step(\n",
        "        \"Iniciando busca evolutiva NSGA-II \"\n",
        "        f\"(população={pop}, gerações={gens}, kfold={kfold}, bootstraps={bootstraps})\"\n",
        "    )\n",
        "    pareto, run_dir = run_nsga(\n",
        "        splits.X_train,\n",
        "        pop_size=pop,\n",
        "        n_gen=gens,\n",
        "        seed=seed,\n",
        "        kfold=kfold,\n",
        "        bootstraps=bootstraps,\n",
        "        outdir=outdir,\n",
        "    )\n",
        "    log_step(f\"Busca evolutiva concluída. Resultados em '{run_dir}'\")\n",
        "\n",
        "    log_step(\"Selecionando solução joelho da frente de Pareto\")\n",
        "    knee_entry = select_knee(pareto)\n",
        "    best_config = model_config_from_jsonable(knee_entry[\"config\"])\n",
        "\n",
        "    log_step(\"Treinando modelo final com treino+validação\")\n",
        "    X_train_full = np.vstack([splits.X_train, splits.X_val])\n",
        "    factory = decode_to_model(best_config)\n",
        "    model = factory()\n",
        "    model.fit(X_train_full)\n",
        "\n",
        "    log_step(\"Avaliando modelo no conjunto de teste\")\n",
        "    test_logp = model.logpdf(splits.X_test)\n",
        "    test_nll = float(-np.mean(test_logp))\n",
        "\n",
        "    log_step(f\"Criando diretórios de saída em '{outdir}'\")\n",
        "    outdir = Path(outdir)\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    figures_dir = outdir / \"figures\"\n",
        "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
        "    models_dir = outdir / \"models\"\n",
        "    models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    log_step(\"Gerando visualizações e salvando artefatos\")\n",
        "    plot_pareto_2d([entry[\"fitness\"] for entry in pareto], figures_dir / \"pareto_2d.png\")\n",
        "    plot_hist_neglogp_test(-test_logp, figures_dir / \"hist_test_logp.png\")\n",
        "    joblib.dump(\n",
        "        {\n",
        "            \"model\": model,\n",
        "            \"scaler\": splits.scaler,\n",
        "            \"config\": best_config.to_jsonable(),\n",
        "        },\n",
        "        models_dir / \"best_model.pkl\",\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        \"test_nll\": test_nll,\n",
        "        \"knee_fitness\": knee_entry[\"fitness\"],\n",
        "        \"knee_config\": knee_entry[\"config\"],\n",
        "        \"pareto_run_dir\": str(run_dir),\n",
        "    }\n",
        "\n",
        "    metrics_path = outdir / \"metrics.json\"\n",
        "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "    log_step(f\"Pipeline concluído. Métricas salvas em '{metrics_path}'\")\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Exemplo de uso (descomente as linhas abaixo para executar no Colab)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "# csv_no_colab = \"/content/winequality-red.csv\"  # ajuste o caminho conforme necessário\n",
        "# resultados = run_pipeline(\n",
        "#     csv_path=csv_no_colab,\n",
        "#     seed=42,\n",
        "#     outdir=\"/content/outputs\",\n",
        "#     pop=60,\n",
        "#     gens=40,\n",
        "#     kfold=3,\n",
        "#     bootstraps=10,\n",
        "# )\n",
        "# resultados\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}